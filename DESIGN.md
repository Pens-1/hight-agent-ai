# hight-agent-ai è©³ç´°è¨­è¨ˆæ›¸

## 1. ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“è¨­è¨ˆ

### 1.1 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦
æœ¬ã‚·ã‚¹ãƒ†ãƒ ã¯ä»¥ä¸‹ã®6ã¤ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Browser (React App)                   â”‚
â”‚                   localhost:5173 (dev)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                             â”‚
             â”‚ HTTP                        â”‚ HTTP (Webhook)
             â–¼                             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  FastAPI       â”‚            â”‚     n8n       â”‚
    â”‚  (API Server)  â”‚            â”‚  (Workflow)   â”‚
    â”‚  :8000         â”‚            â”‚  :5678        â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚       â”‚                        â”‚
         â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                â”‚      â”‚
         â”‚                â–¼      â–¼
         â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚         â”‚     Ollama       â”‚
         â”‚         â”‚   (LLM Service)  â”‚
         â”‚         â”‚     :11434       â”‚
         â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                â”‚
         â”‚                â”‚
         â–¼                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  DeepSeek-OCR Service        â”‚
    â”‚  (FastAPI Wrapper)           â”‚
    â”‚         :8080                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                â”‚
         â”‚                â”‚
         â–¼                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   PostgreSQL + pgvector      â”‚
    â”‚         :5432                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 é€šä¿¡ãƒ•ãƒ­ãƒ¼

#### è³‡æ–™ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ãƒ­ãƒ¼ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ï¼‰
```
1. User â†’ React: ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
2. React â†’ n8n: POST /webhook/upload_document (multipart)
3. n8n â†’ DeepSeek-OCR: ç”»åƒã‚’Markdownã«å¤‰æ›
4. n8n â†’ Ollama: ç§‘ç›®åˆ†é¡ã®ãŸã‚ã®LLMæ¨è«–
5. n8n â†’ Embedding Model: ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
6. n8n â†’ PostgreSQL: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ + ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜
7. n8n â†’ React: Webhookå®Œäº†é€šçŸ¥ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
```

#### å•é¡Œè§£ç­”ãƒ•ãƒ­ãƒ¼ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ï¼‰
```
1. User â†’ React: å•é¡Œç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ + é€ä¿¡
2. React â†’ FastAPI: POST /ask_problem_image
3. FastAPI â†’ DeepSeek-OCR: ç”»åƒã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–
4. FastAPI â†’ Embedding Model: å•é¡Œæ–‡ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
5. FastAPI â†’ PostgreSQL: pgvectorã§é¡ä¼¼ãƒãƒ£ãƒ³ã‚¯æ¤œç´¢
6. FastAPI â†’ Ollama: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ + å•é¡Œã§è§£ç­”ç”Ÿæˆ
7. FastAPI â†’ React: è§£ç­”ï¼ˆMarkdownï¼‰ã‚’è¿”å´
8. React: Markdownãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ï¼ˆæ•°å¼å¯¾å¿œï¼‰
```

---

## 2. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
hight-agent-ai/
â”œâ”€â”€ README.md                    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®èª¬æ˜
â”œâ”€â”€ ä»•æ§˜æ›¸.md                    # è¦ä»¶å®šç¾©ï¼ˆæ—¢å­˜ï¼‰
â”œâ”€â”€ DESIGN.md                    # æœ¬è¨­è¨ˆæ›¸
â”œâ”€â”€ docker-compose.yml           # å…¨ã‚µãƒ¼ãƒ“ã‚¹ã®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
â”œâ”€â”€ .env.example                 # ç’°å¢ƒå¤‰æ•°ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
â”‚
â”œâ”€â”€ frontend/                    # React ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ main.tsx
â”‚       â”œâ”€â”€ App.tsx
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ ChatInterface.tsx      # ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆç”»é¢
â”‚       â”‚   â”œâ”€â”€ DocumentManager.tsx    # è³‡æ–™ç®¡ç†ç”»é¢
â”‚       â”‚   â”œâ”€â”€ ImageUploader.tsx      # ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å…±é€šã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
â”‚       â”‚   â”œâ”€â”€ MarkdownRenderer.tsx   # æ•°å¼å¯¾å¿œMarkdownãƒ¬ãƒ³ãƒ€ãƒ©ãƒ¼
â”‚       â”‚   â””â”€â”€ SettingsPanel.tsx      # RAG/Webæ¤œç´¢ãƒˆã‚°ãƒ«
â”‚       â”œâ”€â”€ hooks/
â”‚       â”‚   â”œâ”€â”€ useChat.ts             # ãƒãƒ£ãƒƒãƒˆçŠ¶æ…‹ç®¡ç†
â”‚       â”‚   â””â”€â”€ useDocuments.ts        # è³‡æ–™ç®¡ç†çŠ¶æ…‹
â”‚       â”œâ”€â”€ services/
â”‚       â”‚   â”œâ”€â”€ api.ts                 # FastAPIé€šä¿¡
â”‚       â”‚   â””â”€â”€ n8nApi.ts              # n8n Webhooké€šä¿¡
â”‚       â”œâ”€â”€ types/
â”‚       â”‚   â””â”€â”€ index.ts               # TypeScriptå‹å®šç¾©
â”‚       â””â”€â”€ styles/
â”‚           â””â”€â”€ global.css             # TailwindCSSè¨­å®š
â”‚
â”œâ”€â”€ backend/                     # FastAPI ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”œâ”€â”€ main.py                  # FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py            # ç’°å¢ƒå¤‰æ•°ãƒ»è¨­å®š
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ health.py          # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
â”‚   â”‚   â”‚       â”œâ”€â”€ ask_problem.py     # å•é¡Œè§£ç­”ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
â”‚   â”‚   â”‚       â””â”€â”€ documents.py       # è³‡æ–™ä¸€è¦§å–å¾—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ocr_service.py         # DeepSeek-OCRå‘¼ã³å‡ºã—
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_service.py         # Ollamaå‘¼ã³å‡ºã—
â”‚   â”‚   â”‚   â”œâ”€â”€ embedding_service.py   # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«
â”‚   â”‚   â”‚   â””â”€â”€ rag_service.py         # RAGæ¤œç´¢ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ connection.py          # PostgreSQLæ¥ç¶š
â”‚   â”‚   â”‚   â””â”€â”€ repositories/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ document_repo.py   # documentsãƒ†ãƒ¼ãƒ–ãƒ«æ“ä½œ
â”‚   â”‚   â”‚       â””â”€â”€ chunk_repo.py      # chunksãƒ†ãƒ¼ãƒ–ãƒ«æ“ä½œ
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py             # Pydanticãƒ¢ãƒ‡ãƒ«
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ logger.py              # ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ ocr-service/                 # DeepSeek-OCR ã‚µãƒ¼ãƒ“ã‚¹
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ main.py                  # FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚   â”‚       â””â”€â”€ ocr.py             # POST /ocr ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ deepseek_ocr.py        # DeepSeek-OCRãƒ©ãƒƒãƒ‘ãƒ¼
â”‚   â””â”€â”€ tests/
â”‚       â””â”€â”€ test_ocr.py
â”‚
â”œâ”€â”€ n8n/                         # n8n ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â””â”€â”€ document_upload.json       # è³‡æ–™ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
â”‚   â””â”€â”€ README.md                      # n8nã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †
â”‚
â”œâ”€â”€ database/                    # PostgreSQL åˆæœŸåŒ–
â”‚   â”œâ”€â”€ init.sql                 # DBãƒ»ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”‚   â””â”€â”€ Dockerfile               # PostgreSQL + pgvector
â”‚
â””â”€â”€ scripts/                     # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
    â”œâ”€â”€ setup_ollama.sh          # OllamaåˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰
    â”œâ”€â”€ test_all_services.sh     # å…¨ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    â””â”€â”€ clean_db.sh              # DBåˆæœŸåŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```

---

## 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ

### 3.1 ã‚¹ã‚­ãƒ¼ãƒå®šç¾©

```sql
-- æ‹¡å¼µæ©Ÿèƒ½ã®æœ‰åŠ¹åŒ–
CREATE EXTENSION IF NOT EXISTS vector;

-- è³‡æ–™ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    filename TEXT NOT NULL,
    subject TEXT,                          -- LLMã«ã‚ˆã‚‹åˆ†é¡ç§‘ç›®
    original_path TEXT,                     -- å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜ç”¨ï¼‰
    status TEXT NOT NULL DEFAULT 'processing', -- processing | completed | failed
    error_message TEXT,                     -- å¤±æ•—æ™‚ã®ã‚¨ãƒ©ãƒ¼å†…å®¹
    file_size_bytes BIGINT,                -- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
    mime_type TEXT,                        -- MIMEã‚¿ã‚¤ãƒ—
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- è³‡æ–™ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_documents_status ON documents(status);
CREATE INDEX idx_documents_subject ON documents(subject);
CREATE INDEX idx_documents_created_at ON documents(created_at DESC);

-- RAGç”¨ãƒãƒ£ãƒ³ã‚¯ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE chunks (
    id SERIAL PRIMARY KEY,
    document_id INTEGER NOT NULL REFERENCES documents(id) ON DELETE CASCADE,
    content TEXT NOT NULL,                 -- åˆ†å‰²ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆæœ¬æ–‡
    chunk_index INTEGER NOT NULL,          -- ãƒãƒ£ãƒ³ã‚¯é †åº
    embedding VECTOR(1024) NOT NULL,       -- multilingual-e5-large (1024æ¬¡å…ƒ)
    metadata JSONB,                        -- è¿½åŠ æƒ…å ±ï¼ˆãƒšãƒ¼ã‚¸ç•ªå·ãªã©ï¼‰
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ãƒãƒ£ãƒ³ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_chunks_document_id ON chunks(document_id);
CREATE INDEX idx_chunks_chunk_index ON chunks(document_id, chunk_index);

-- ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦æ¤œç´¢ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆHNSWï¼‰
CREATE INDEX idx_chunks_embedding ON chunks 
USING hnsw (embedding vector_cosine_ops) 
WITH (m = 16, ef_construction = 64);

-- ä¼šè©±å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼šå°†æ¥çš„ãªæ‹¡å¼µï¼‰
CREATE TABLE conversations (
    id SERIAL PRIMARY KEY,
    session_id TEXT NOT NULL,
    question TEXT NOT NULL,
    question_image_path TEXT,              -- å•é¡Œç”»åƒã®ãƒ‘ã‚¹
    answer TEXT NOT NULL,
    used_rag BOOLEAN DEFAULT TRUE,
    used_web_search BOOLEAN DEFAULT FALSE,
    referenced_chunks INTEGER[],           -- å‚ç…§ã—ãŸchunk IDã®é…åˆ—
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_conversations_session_id ON conversations(session_id);
CREATE INDEX idx_conversations_created_at ON conversations(created_at DESC);
```

### 3.2 ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

**è³‡æ–™ç™»éŒ²æ™‚**
```
documents ãƒ†ãƒ¼ãƒ–ãƒ«
  â†“ (1ä»¶æŒ¿å…¥: status='processing')
  â†“
OCR + ãƒãƒ£ãƒ³ã‚¯åˆ†å‰² + åŸ‹ã‚è¾¼ã¿
  â†“
chunks ãƒ†ãƒ¼ãƒ–ãƒ«
  â†“ (Nä»¶æŒ¿å…¥: document_idå¤–éƒ¨ã‚­ãƒ¼)
  â†“
documents.status ã‚’ 'completed' ã«æ›´æ–°
```

**RAGæ¤œç´¢æ™‚**
```
1. å•é¡Œæ–‡ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
2. chunksãƒ†ãƒ¼ãƒ–ãƒ«ã§ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦æ¤œç´¢
   SELECT content, document_id 
   FROM chunks 
   ORDER BY embedding <=> $1::vector 
   LIMIT 5;
3. documentsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
4. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
```

---

## 4. ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè©³ç´°è¨­è¨ˆ

### 4.1 FastAPI ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰

#### 4.1.1 ä¸»è¦ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

**POST /api/ask_problem_image**
```python
# ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
{
    "image": File,                    # å•é¡Œç”»åƒï¼ˆmultipartï¼‰
    "use_rag": bool = True,          # RAGæ¤œç´¢ã‚’ä½¿ç”¨ã™ã‚‹ã‹
    "use_web_search": bool = False,  # Webæ¤œç´¢ã‚’ä½¿ç”¨ã™ã‚‹ã‹ï¼ˆå°†æ¥å®Ÿè£…ï¼‰
    "session_id": str = None         # ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
}

# ãƒ¬ã‚¹ãƒãƒ³ã‚¹
{
    "answer": str,                    # Markdownå½¢å¼ã®è§£ç­”
    "referenced_documents": [         # RAGä½¿ç”¨æ™‚ã®å‚ç…§è³‡æ–™
        {
            "document_id": int,
            "filename": str,
            "subject": str,
            "chunk_content": str      # ä½¿ç”¨ã—ãŸãƒãƒ£ãƒ³ã‚¯å†…å®¹ã®ä¸€éƒ¨
        }
    ],
    "processing_time_ms": int
}
```

**POST /api/ask_problem_text**
```python
# ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
{
    "question": str,                  # ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®è³ªå•
    "use_rag": bool = True,
    "use_web_search": bool = False,
    "session_id": str = None
}

# ãƒ¬ã‚¹ãƒãƒ³ã‚¹
# ask_problem_imageã¨åŒã˜
```

**GET /api/documents**
```python
# ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
{
    "status": str = None,             # ãƒ•ã‚£ãƒ«ã‚¿: processing | completed | failed
    "subject": str = None,            # ãƒ•ã‚£ãƒ«ã‚¿: ç§‘ç›®å
    "limit": int = 50,
    "offset": int = 0
}

# ãƒ¬ã‚¹ãƒãƒ³ã‚¹
{
    "documents": [
        {
            "id": int,
            "filename": str,
            "subject": str,
            "status": str,
            "created_at": str,
            "chunk_count": int        # ç´ã¥ããƒãƒ£ãƒ³ã‚¯æ•°
        }
    ],
    "total": int
}
```

**DELETE /api/documents/{document_id}**
```python
# ãƒ¬ã‚¹ãƒãƒ³ã‚¹
{
    "success": bool,
    "message": str
}
```

**GET /api/health**
```python
# ãƒ¬ã‚¹ãƒãƒ³ã‚¹
{
    "status": "ok",
    "services": {
        "database": "ok" | "error",
        "ollama": "ok" | "error",
        "ocr": "ok" | "error"
    }
}
```

#### 4.1.2 ã‚µãƒ¼ãƒ“ã‚¹å±¤è¨­è¨ˆ

**RAGService (`app/services/rag_service.py`)**
```python
class RAGService:
    def __init__(self, db_conn, embedding_service, llm_service):
        self.db = db_conn
        self.embedding = embedding_service
        self.llm = llm_service
    
    async def search_relevant_chunks(
        self, 
        query_text: str, 
        top_k: int = 5,
        subject_filter: str = None
    ) -> List[Chunk]:
        """ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§é–¢é€£ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—"""
        query_vector = await self.embedding.embed_text(query_text)
        return await self.db.chunks.vector_search(
            query_vector, 
            top_k, 
            subject_filter
        )
    
    async def build_prompt(
        self, 
        question: str, 
        chunks: List[Chunk]
    ) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
        context = "\n\n".join([
            f"[è³‡æ–™: {c.document.filename} ({c.document.subject})]\n{c.content}"
            for c in chunks
        ])
        
        return f"""ä»¥ä¸‹ã®æˆæ¥­è³‡æ–™ã‚’å‚è€ƒã«ã€å­¦ç”Ÿã®è³ªå•ã«ä¸å¯§ã«è§£ç­”ã—ã¦ãã ã•ã„ã€‚

# å‚è€ƒè³‡æ–™
{context}

# å­¦ç”Ÿã®è³ªå•
{question}

# è§£ç­”
æ•°å¼ã¯LaTeXè¨˜æ³•ï¼ˆ$$...$$ï¼‰ã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
"""
    
    async def generate_answer(
        self, 
        question: str, 
        use_rag: bool = True
    ) -> AnswerResult:
        """è§£ç­”ç”Ÿæˆã®ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        chunks = []
        if use_rag:
            chunks = await self.search_relevant_chunks(question)
        
        prompt = await self.build_prompt(question, chunks) if chunks else question
        answer = await self.llm.generate(prompt)
        
        return AnswerResult(
            answer=answer,
            referenced_chunks=chunks
        )
```

**EmbeddingService (`app/services/embedding_service.py`)**
```python
from sentence_transformers import SentenceTransformer

class EmbeddingService:
    def __init__(self, model_name: str = "intfloat/multilingual-e5-large"):
        self.model = SentenceTransformer(model_name)
    
    async def embed_text(self, text: str) -> List[float]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆéåŒæœŸå¯¾å¿œï¼‰"""
        # multilingual-e5ã§ã¯ã€æ¤œç´¢ã‚¯ã‚¨ãƒªã«ã¯"query: "ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’ä»˜ã‘ã‚‹
        prefixed = f"query: {text}"
        embedding = self.model.encode(prefixed, normalize_embeddings=True)
        return embedding.tolist()
    
    async def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """è¤‡æ•°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒãƒƒãƒã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã¯"passage: "ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’ä»˜ã‘ã‚‹
        prefixed = [f"passage: {text}" for text in texts]
        embeddings = self.model.encode(prefixed, normalize_embeddings=True, batch_size=32)
        return embeddings.tolist()
```

**LLMService (`app/services/llm_service.py`)**
```python
import aiohttp

class OllamaService:
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.model = "qwen3:30b-instruct"  # è¨­å®šã‹ã‚‰èª­ã¿è¾¼ã¿
    
    async def generate(
        self, 
        prompt: str, 
        system: str = None,
        temperature: float = 0.7
    ) -> str:
        """Ollamaã§æ–‡ç« ç”Ÿæˆ"""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "system": system,
                    "temperature": temperature,
                    "stream": False
                }
            ) as response:
                result = await response.json()
                return result["response"]
    
    async def classify_subject(self, text: str) -> str:
        """è³‡æ–™ã®ç§‘ç›®åˆ†é¡"""
        prompt = f"""ä»¥ä¸‹ã®æˆæ¥­è³‡æ–™ã®å†…å®¹ã‚’åˆ†æã—ã€ç§‘ç›®ã‚’1ã¤é¸ã‚“ã§ãã ã•ã„ã€‚

è³‡æ–™å†…å®¹:
{text[:2000]}  # æœ€åˆã®2000æ–‡å­—ã®ã¿

ç§‘ç›®ãƒªã‚¹ãƒˆ: æ•°å­¦, ç‰©ç†(åŠ›å­¦), ç‰©ç†(é›»ç£æ°—), ç‰©ç†(ç†±åŠ›å­¦), ç‰©ç†(é‡å­åŠ›å­¦), åŒ–å­¦, ç”Ÿç‰©å­¦, ãã®ä»–

å›ç­”ã¯ç§‘ç›®åã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"""
        
        return (await self.generate(prompt)).strip()
```

**OCRService (`app/services/ocr_service.py`)**
```python
import aiohttp

class DeepSeekOCRService:
    def __init__(self, base_url: str = "http://localhost:8080"):
        self.base_url = base_url
    
    async def extract_text(self, image_bytes: bytes) -> str:
        """ç”»åƒã‹ã‚‰Markdownå½¢å¼ã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º"""
        async with aiohttp.ClientSession() as session:
            form = aiohttp.FormData()
            form.add_field('image', image_bytes, filename='image.png', content_type='image/png')
            
            async with session.post(
                f"{self.base_url}/api/ocr",
                data=form
            ) as response:
                result = await response.json()
                return result["markdown"]
```

### 4.2 OCR Service

#### 4.2.1 ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

**POST /api/ocr**
```python
# ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
{
    "image": File  # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆmultipartï¼‰
}

# ãƒ¬ã‚¹ãƒãƒ³ã‚¹
{
    "markdown": str,              # æŠ½å‡ºã•ã‚ŒãŸMarkdownãƒ†ã‚­ã‚¹ãƒˆ
    "processing_time_ms": int
}
```

#### 4.2.2 å®Ÿè£…ä¾‹ï¼ˆ`ocr-service/main.py`ï¼‰

```python
from fastapi import FastAPI, File, UploadFile
from deepseek_ocr import DeepSeekOCR  # ä»®æƒ³ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import time

app = FastAPI()
ocr_model = DeepSeekOCR()  # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–

@app.post("/api/ocr")
async def extract_text(image: UploadFile = File(...)):
    start = time.time()
    
    image_bytes = await image.read()
    markdown = ocr_model.process(image_bytes)
    
    return {
        "markdown": markdown,
        "processing_time_ms": int((time.time() - start) * 1000)
    }

@app.get("/health")
async def health():
    return {"status": "ok"}
```

### 4.3 n8n ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¨­è¨ˆ

#### 4.3.1 ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼: è³‡æ–™ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†

**ãƒãƒ¼ãƒ‰æ§‹æˆ**
```
1. Webhook (POST /webhook/upload_document)
   â†“
2. Function: ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—
   â†“
3. HTTP Request: OCR Service (ç”»åƒâ†’Markdown)
   â†“
4. Function: ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ï¼ˆ1000æ–‡å­—/ãƒãƒ£ãƒ³ã‚¯ã€200æ–‡å­—ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ï¼‰
   â†“
5. HTTP Request: Ollama (ç§‘ç›®åˆ†é¡)
   â†“
6. PostgreSQL: documentsãƒ†ãƒ¼ãƒ–ãƒ«ã«INSERT
   â†“
7. Loop: å„ãƒãƒ£ãƒ³ã‚¯ã«ã¤ã„ã¦
   â”œâ”€ HTTP Request: Embedding Service (FastAPIã«è¿½åŠ å®Ÿè£…)
   â””â”€ PostgreSQL: chunksãƒ†ãƒ¼ãƒ–ãƒ«ã«INSERT
   â†“
8. PostgreSQL: documentsã®statusã‚’'completed'ã«æ›´æ–°
   â†“
9. Response: å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
```

**ä¸»è¦ãƒãƒ¼ãƒ‰è¨­å®š**

*Webhook Node*
```json
{
  "method": "POST",
  "path": "/webhook/upload_document",
  "responseMode": "lastNode",
  "options": {
    "rawBody": false
  }
}
```

*Function Node: ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²*
```javascript
// n8nã®Function Nodeå†…ã§å®Ÿè¡Œ
const text = items[0].json.markdown;
const chunkSize = 1000;
const overlap = 200;
const chunks = [];

for (let i = 0; i < text.length; i += (chunkSize - overlap)) {
  chunks.push({
    content: text.slice(i, i + chunkSize),
    chunk_index: chunks.length
  });
}

return chunks.map(chunk => ({ json: chunk }));
```

### 4.4 ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¨­è¨ˆ

#### 4.4.1 ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

**ChatInterface.tsx**
```typescript
interface Message {
  id: string;
  type: 'user' | 'assistant';
  content: string;
  image?: string;  // Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç”»åƒ
  referencedDocs?: ReferencedDocument[];
  timestamp: Date;
}

const ChatInterface: React.FC = () => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState('');
  const [useRAG, setUseRAG] = useState(true);
  const [isLoading, setIsLoading] = useState(false);
  
  const handleImageUpload = async (file: File) => {
    // ç”»åƒã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
    // FastAPIã«POST
    // ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦è¿½åŠ 
  };
  
  return (
    <div className="flex flex-col h-screen">
      <Header />
      <SettingsPanel useRAG={useRAG} setUseRAG={setUseRAG} />
      <MessageList messages={messages} />
      <InputArea 
        onSendText={handleTextSend}
        onSendImage={handleImageUpload}
      />
    </div>
  );
};
```

**DocumentManager.tsx**
```typescript
interface Document {
  id: number;
  filename: string;
  subject: string;
  status: 'processing' | 'completed' | 'failed';
  created_at: string;
  chunk_count: number;
}

const DocumentManager: React.FC = () => {
  const { documents, loading, error } = useDocuments();
  
  const handleUpload = async (file: File) => {
    // n8n Webhookã«é€ä¿¡
    const formData = new FormData();
    formData.append('file', file);
    await axios.post('http://localhost:5678/webhook/upload_document', formData);
  };
  
  const handleDelete = async (id: number) => {
    await axios.delete(`http://localhost:8000/api/documents/${id}`);
  };
  
  return (
    <div>
      <FileUploader onUpload={handleUpload} />
      <DocumentTable 
        documents={documents} 
        onDelete={handleDelete}
      />
    </div>
  );
};
```

**MarkdownRenderer.tsx**
```typescript
import ReactMarkdown from 'react-markdown';
import remarkMath from 'remark-math';
import rehypeKatex from 'rehype-katex';
import 'katex/dist/katex.min.css';

const MarkdownRenderer: React.FC<{ content: string }> = ({ content }) => {
  return (
    <ReactMarkdown
      remarkPlugins={[remarkMath]}
      rehypePlugins={[rehypeKatex]}
      components={{
        code: ({ node, inline, className, children, ...props }) => {
          // ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
        }
      }}
    >
      {content}
    </ReactMarkdown>
  );
};
```

---

## 5. ç’°å¢ƒæ§‹ç¯‰

### 5.1 Docker Composeæ§‹æˆ

```yaml
version: '3.8'

services:
  # PostgreSQL + pgvector
  postgres:
    build: ./database
    container_name: hight-ai-db
    environment:
      POSTGRES_DB: hight_ai
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Ollama
  ollama:
    image: ollama/ollama:latest
    container_name: hight-ai-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]  # GPUä½¿ç”¨æ™‚

  # OCR Service
  ocr-service:
    build: ./ocr-service
    container_name: hight-ai-ocr
    ports:
      - "8080:8080"
    environment:
      - MODEL_PATH=/models
    volumes:
      - ./models:/models
    depends_on:
      - postgres

  # FastAPI Backend
  backend:
    build: ./backend
    container_name: hight-ai-backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://admin:${DB_PASSWORD}@postgres:5432/hight_ai
      - OLLAMA_URL=http://ollama:11434
      - OCR_URL=http://ocr-service:8080
    volumes:
      - ./backend:/app
      - upload_files:/app/uploads
    depends_on:
      - postgres
      - ollama
      - ocr-service
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload

  # n8n
  n8n:
    image: n8nio/n8n:latest
    container_name: hight-ai-n8n
    ports:
      - "5678:5678"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=admin
      - N8N_BASIC_AUTH_PASSWORD=${N8N_PASSWORD}
      - N8N_HOST=localhost
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - WEBHOOK_URL=http://localhost:5678/
    volumes:
      - n8n_data:/home/node/.n8n
      - ./n8n/workflows:/home/node/.n8n/workflows
    depends_on:
      - postgres
      - ollama
      - ocr-service

  # Frontend (é–‹ç™ºç’°å¢ƒ)
  frontend:
    build: ./frontend
    container_name: hight-ai-frontend
    ports:
      - "5173:5173"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      - VITE_API_URL=http://localhost:8000
      - VITE_N8N_WEBHOOK_URL=http://localhost:5678/webhook/upload_document
    command: npm run dev

volumes:
  postgres_data:
  ollama_data:
  n8n_data:
  upload_files:
```

### 5.2 ç’°å¢ƒå¤‰æ•°ï¼ˆ.envï¼‰

```bash
# Database
DB_PASSWORD=your_secure_password

# n8n
N8N_PASSWORD=your_n8n_password

# Ollama
OLLAMA_MODEL=qwen3:30b-instruct

# Embedding
EMBEDDING_MODEL=intfloat/multilingual-e5-large

# OCR
OCR_MODEL_PATH=/path/to/deepseek-ocr
```

---

## 6. ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

### 6.1 åˆå›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# 1. ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/your-org/hight-agent-ai.git
cd hight-agent-ai

# 2. ç’°å¢ƒå¤‰æ•°è¨­å®š
cp .env.example .env
# .envã‚’ç·¨é›†

# 3. Dockerã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•
docker-compose up -d

# 4. Ollamaãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
docker exec -it hight-ai-ollama ollama pull qwen3:30b-instruct

# 5. åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆbackendã‚³ãƒ³ãƒ†ãƒŠå†…ã§å®Ÿè¡Œï¼‰
docker exec -it hight-ai-backend python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('intfloat/multilingual-e5-large')"

# 6. n8nãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:5678 ã«ã‚¢ã‚¯ã‚»ã‚¹
# n8n/workflows/document_upload.json ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

# 7. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚¢ã‚¯ã‚»ã‚¹
# http://localhost:5173
```

### 6.2 é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰

```bash
# Backend
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
uvicorn main:app --reload

# Frontend
cd frontend
npm install
npm run dev
```

---

## 7. å®Ÿè£…ã®å„ªå…ˆé †ä½

### Phase 1: MVPï¼ˆæœ€å°æ§‹æˆï¼‰
1. âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆãƒ»ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
2. âœ… FastAPIåŸºæœ¬æ§‹é€  + ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
3. âœ… OCR ServiceåŸºæœ¬å®Ÿè£…
4. âœ… Ollamaé€£æºå®Ÿè£…
5. âœ… åŸ‹ã‚è¾¼ã¿ã‚µãƒ¼ãƒ“ã‚¹å®Ÿè£…
6. âœ… RAGæ¤œç´¢æ©Ÿèƒ½å®Ÿè£…
7. âœ… POST /ask_problem_image å®Ÿè£…
8. âœ… ReactåŸºæœ¬UIï¼ˆãƒãƒ£ãƒƒãƒˆç”»é¢ï¼‰
9. âœ… ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰â†’è§£ç­”è¡¨ç¤ºã®E2Eãƒ†ã‚¹ãƒˆ

### Phase 2: è³‡æ–™ç®¡ç†æ©Ÿèƒ½
1. âœ… n8nãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹ç¯‰ï¼ˆè³‡æ–™ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰
2. âœ… POST /webhook/upload_document å®Ÿè£…
3. âœ… ç§‘ç›®è‡ªå‹•åˆ†é¡å®Ÿè£…
4. âœ… ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ãƒ»ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ»DBç™»éŒ²
5. âœ… Reactè³‡æ–™ç®¡ç†ç”»é¢
6. âœ… è³‡æ–™ä¸€è¦§ãƒ»å‰Šé™¤æ©Ÿèƒ½

### Phase 3: å“è³ªå‘ä¸Š
1. âœ… ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–
2. âœ… ãƒ­ã‚®ãƒ³ã‚°æ•´å‚™
3. âœ… UI/UXæ”¹å–„ï¼ˆãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¡¨ç¤ºã€ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºï¼‰
4. âœ… Markdown/æ•°å¼ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°æœ€é©åŒ–
5. âœ… ãƒ¬ã‚¹ãƒãƒ³ã‚¹é€Ÿåº¦æ”¹å–„

### Phase 4: æ‹¡å¼µæ©Ÿèƒ½ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
1. ğŸ”² Webæ¤œç´¢æ©Ÿèƒ½ï¼ˆSearXNGé€£æºï¼‰
2. ğŸ”² ä¼šè©±å±¥æ­´æ©Ÿèƒ½
3. ğŸ”² è¤‡æ•°ãƒ¢ãƒ‡ãƒ«åˆ‡ã‚Šæ›¿ãˆ
4. ğŸ”² ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šä¿å­˜
5. ğŸ”² ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½ï¼ˆPDF/Markdownï¼‰

---

## 8. ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### 8.1 å˜ä½“ãƒ†ã‚¹ãƒˆ
- Backend: pytest + pytest-asyncio
- Frontend: Vitest + React Testing Library

### 8.2 çµ±åˆãƒ†ã‚¹ãƒˆ
- API E2Eãƒ†ã‚¹ãƒˆ: Postman/pytest-httpx
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ: ãƒ†ã‚¹ãƒˆç”¨DBã§ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç¢ºèª

### 8.3 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
- RAGæ¤œç´¢é€Ÿåº¦: ç›®æ¨™ < 500ms
- LLMæ¨è«–é€Ÿåº¦: ç›®æ¨™ < 10ç§’ï¼ˆQwen3-30Bï¼‰
- OCRå‡¦ç†é€Ÿåº¦: ç›®æ¨™ < 2ç§’

---

## 9. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®äº‹é …

1. **ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰åˆ¶é™**
   - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºä¸Šé™: 10MB
   - è¨±å¯ã™ã‚‹æ‹¡å¼µå­: .pdf, .png, .jpg, .jpeg

2. **SQL ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–**
   - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒªä½¿ç”¨ï¼ˆpsycopg2/asyncpgï¼‰

3. **XSSå¯¾ç­–**
   - Reactæ¨™æº–ã®ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—æ©Ÿèƒ½
   - react-markdownã®å®‰å…¨ãªè¨­å®š

4. **CORSè¨­å®š**
   - é–‹ç™ºç’°å¢ƒ: å…¨ã¦è¨±å¯
   - æœ¬ç•ªç’°å¢ƒ: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®ã‚ªãƒªã‚¸ãƒ³ã®ã¿è¨±å¯

---

## 10. ä»Šå¾Œã®èª²é¡Œ

1. **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**
   - å¤§é‡ã®è³‡æ–™ç™»éŒ²æ™‚ã®ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢é€Ÿåº¦
   - ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼å°å…¥ï¼ˆCelery/Redisï¼‰

2. **ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–**
   - é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã®æ¤œè¨ï¼ˆGGUFå½¢å¼ï¼‰
   - GPU/CPUè‡ªå‹•åˆ‡ã‚Šæ›¿ãˆ

3. **ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£**
   - ã‚ªãƒ³ãƒœãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
   - ã‚µãƒ³ãƒ—ãƒ«è³‡æ–™ã®æä¾›

4. **ç›£è¦–ãƒ»é‹ç”¨**
   - Prometheusã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
   - Grafanaã§ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ§‹ç¯‰

