プロジェクト「hight-agent-ai」基本仕様書
1. プロジェクト概要


項目
内容
プロジェクト名
hight-agent-ai
目的
理系大学の学部初期課程（一回生など）の学生を対象に、数学・物理などの学習を支援する。特に、教科書や授業資料に基づいた（RAG）問題の解説・解答生成をローカル環境で完結して提供する。
主な利用者
理系の大学生、大学院生、または関連分野を学習する社会人。
コンセプト
1. ローカル完結: ユーザーのプライバシー（授業資料、質問履歴）を守るため、全ての処理（LLM推論、OCR、DB）をユーザーのローカルマシン上で完結させる。

2. RAGファースト: 汎用的な知識だけでなく、ユーザーがアップロードした授業資料や教科書に基づいた、精度の高い解答を提供する。

3. 自動化: アップロードされた資料の科目分類、テキスト化、RAG登録を自動で行い、ユーザーの手間を最小限にする。

2. システムアーキテクチャ
本システムは、機能の役割（リアルタイム性 vs バックグラウンド処理）に応じて、複数のローカルサーバーコンポーネントが連携して動作するマイクロサービスアーキテクチャを採用する。
2.1. 構成図
[ユーザー (ブラウザ)]
    |
    | (React App)
    +---------------------------+
    |                           |
[リアルタイム処理]          [バックグラウンド処理]
    | (HTTP/S)                  | (HTTP/S Webhook)
    v                           v
[FastAPI サーバー]            [n8n サーバー]
(ローカル:8000)             (ローカル:5678)
    | \                         |
    |  `----. (HTTP)           | (HTTP)
    |       |                   |
    |       v                   v
    |   [Ollama (Qwen3)]      [DeepSeek-OCR API]
    |   (ローカル:11434)      (ローカル:8080)
    |       |                   |
    |       `----------------.  |
    |                         | |
    `---------> [PostgreSQL + pgvector] <'
                (ローカル:5432)


2.2. コンポーネントの役割
コンポーネント
役割
フロントエンド (React)
ユーザーが操作する全てのUIを提供。Viteによるビルドを想定。
APIサーバー (FastAPI)
(リアルタイム処理担当) Reactからの「問題解答」リクエストを受け付け、RAG検索、LLM推論をオーケストレーションし、即座に解答を返す。
ワークフロー (n8n)
(バックグラウンド処理担当) Reactからの「資料アップロード」リクエストをWebhookで受け付け、OCR、分類、ベクトル化、DB登録の一連の重い処理を非同期で実行する。
LLMサービス (Ollama)
Qwen3 (30B) をローカルAPIとして提供。FastAPI (解答生成) と n8n (資料分類) の両方から呼び出される。
OCRサービス (DeepSeek-OCR)
DeepSeek-OCRをFastAPIなどでラップしたPythonサーバー。画像（問題、資料）をMarkdownテキストに変換する。
DB (PostgreSQL)
pgvector拡張を有効化。資料のメタデータ (SQL) とテキストチャンクのベクトル (Vector) を一元管理する。
埋め込みモデル
intfloat/multilingual-e5-large などをローカルでロード。n8n (登録時) と FastAPI (検索時) で使用される。

3. 機能要件
F1: 資料管理機能 (主に n8n / React)
ID
機能名
詳細
F1-1
資料アップロード
ユーザーはReactのUIから資料（PDF、画像ファイル）をアップロードできる。Reactはn8nのWebhookエンドポイントにファイルをPOSTする。
F1-2
資料の自動分類
[n8n] アップロードされた資料をOCRでテキスト化し、その内容を Ollama (Qwen3) に送り、科目（例: "数学", "物理(力学)"）を自動で分類させる。
F1-3
資料の自動テキスト化
[n8n] 資料が画像やスキャンPDFの場合、DeepSeek-OCRサービスを呼び出し、全文をMarkdownテキストとして抽出する。
F1-4
資料の自動RAG登録
[n8n] 抽出したテキストをチャンクに分割し、埋め込みモデルでベクトル化。F1-2の分類結果と共にPostgreSQL (pgvector) に保存する。

F2: 問題解答機能 (主に FastAPI / React)
ID
機能名
詳細
F2-1
問題の画像アップロード
ユーザーはReactのUIから問題（手書き、印刷）の写真をアップロードできる。
F2-2
問題のテキスト化
[FastAPI] アップロードされた画像をDeepSeek-OCRサービスに送り、Markdown形式（数式はLaTeX）のテキストを取得する。
F2-3
解答生成 (RAG + LLM)
[FastAPI] OCRテキストをベクトル化し、pgvectorで関連する授業資料を検索。プロンプト（コンテキスト＋問題）を構築し、 Ollama (Qwen3) に解答を生成させる。これがデフォルトの解答モード。
F2-4
解答生成 (LLM単体)
ユーザーがRAGをオフにした場合、資料を参照せず、LLMの知識のみで解答を生成するモード。
F2-5
解答生成 (Web検索)
[オプション] ユーザーがWeb検索をオンにした場合、ローカルのSearXNGや外部APIを叩き、検索結果をコンテキストに含めて解答を生成する。

F3: UI機能 (React)
ID
機能名
詳細
F3-1
メインチャット画面
ChatGPTライクなチャットインターフェース。画像アップロード機能、テキスト入力、解答のMarkdown表示（数式対応）、RAG/Web検索のトグルスイッチを持つ。
F3-2
資料管理画面
アップロード済みの資料を一覧表示。科目、ファイル名、処理ステータス（処理中/完了）を確認・削除できる。

4. 非機能要件
ID
項目
詳細
NF1
ローカル完結
(最重要) 全てのコンポーネント (React, FastAPI, n8n, DB, Ollama, OCR) は、インターネット接続なしでローカルマシン上で動作可能であること。
NF2
パフォーマンス
F2 (問題解答機能) は、ユーザー体験を損なわないよう、リクエストから5〜10秒以内（モデルの推論時間に依存）にレスポンスを返すことを目指す。
NF3
セキュリティ
全てのデータ（資料、質問履歴）はローカルのPostgreSQLに保存され、外部に送信されないこと。
NF4
拡張性
LLMモデル (Ollama)、OCRモデル、埋め込みモデルは、設定ファイルやコードの最小限の変更で差し替え可能であること。
NF5
クロスプラットフォーム
可能な限り、Windows, macOS, Linuxで動作すること (Dockerの活用を推奨)。

5. 技術スタック（詳細）
領域
技術
ライブラリ / ツール
フロントエンド
React (TypeScript)
vite, axios, react-markdown, tailwindcss
リアルタイムAPI
Python (FastAPI)
uvicorn, langchain or llama-index, psycopg2 (pgvector)
バックグラウンド
n8n
n8n (Dockerイメージ)
データベース
PostgreSQL
postgresql:16, pgvector 拡張
LLM
Ollama
ollama, qwen3:30b-instruct (または必要に応じ小規模モデル)
OCR
Python (FastAPI/Flask)
deepseek-ocr (Pythonラッパー), pillow
埋め込み
-
sentence-transformers (e.g., intfloat/multilingual-e5-large)

6. 主要APIエンドポイント（案）
6.1. FastAPI (ローカル:8000)
POST /ask_problem_image
説明: 画像による質問を受け付け、RAG/Web検索を駆使して解答を返す。
リクエスト: multipart/form-data (画像ファイル, RAG利用フラグ, Web検索フラグ)
レスポンス: JSON (解答テキスト(Markdown), 参照資料)
POST /ask_problem_text
説明: テキストによる質問を受け付ける。
リクエスト: JSON (質問テキスト, RAG利用フラグ, Web検索フラグ)
レスポンス: JSON (解答テキスト(Markdown), 参照資料)
6.2. n8n (ローカル:5678)
POST /webhook/upload_document
説明: 授業資料のアップロードを受け付けるWebhook。
リクエスト: multipart/form-data (ファイル)
レスポンス: JSON (受付成功メッセージ) - 処理自体は非同期で実行。
7. データベーススキーマ（案）
テーブル: documents (資料メタデータ)
id (SERIAL, PRIMARY KEY): 資料ID
filename (TEXT, NOT NULL): 元のファイル名
subject (TEXT): LLMによる分類科目 (例: "数学")
status (TEXT): T処理ステータス (例: "processing", "completed", "failed")
created_at (TIMESTAMP, DEFAULT CURRENT_TIMESTAMP): 登録日時
テーブル: chunks (RAG用データ)
id (SERIAL, PRIMARY KEY): チャンクID
document_id (INTEGER, REFERENCES documents(id) ON DELETE CASCADE): 紐づく資料ID
content (TEXT): 分割されたテキスト本文
embedding (VECTOR(1024)): テキストのベクトル (multilingual-e5-large の場合1024次元)
